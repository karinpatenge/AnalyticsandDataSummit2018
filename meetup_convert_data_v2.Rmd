---
title: Using Property Graph and Graph Analytics together with Oracle NoSQL DB to analyze data from Meetup.com
author: "Karin Patenge, Oracle Deutschland B.V. & Co. KG"
date: "3/14/2018"
output: html_notebook
---
## Last updated: Apr 05,2018

## Acknowledgment
The R code below contains snippets from the following resources:  
- https://gist.github.com/rmoff/17025830c81e60d6446e34a37273f705 (Author: Robin Moffat)   
- https://cran.r-project.org/web/packages/jsonlite/vignettes/json-apis.html  

## Abstract
The following code is used to retrieve data from social media platform Meetup.com (http://www.meetup.com) via Meetup´s REST API (http://www.meetup.com/meetup_api ) to be stored in an Oracle NoSQL DB (www.oracle.com/technetwork/database/database-technologies/nosqldb) and analyzed using Oracle´s Graph Technologies on a Big Data Platform (http://www.oracle.com/technetwork/database/database-technologies/bigdata-spatialandgraph).

## General Information
Documentation for Big Data Spatial and Graph (Property Graph Support) can be found on:
https://docs.oracle.com/bigdata/bda411/BDSPA/using-property-graphs-big-data.htm#BDSPA-GUID-C20DE69B-322D-4FBE-B132-507C784F4581  

The code has been tested using Big Data Lite VM 4.11 that is available for free via http://www.oracle.com/technetwork/database/bigdata-appliance/oracle-bigdatalite-2104726.html. The only prerequisite is to register to the Oracle Technology Network (OTN).

## Known Problems
There might be occasional error messages stating *Error in parse_con(txt, bigint_as_char) : parse error: premature EOF* when reading data via REST API requests using jsonlite. I haven´t found yet a stable solution around this error. It might occur sending requests from behind a firewall or when in a network with low bandwidth.

## Data Preparation Workflow
The whole workflow describes how to retrieve data from Meetup.com via its REST API and which transformation steps are necessary to create Oracle's Flat File format containing all nodes and edges extracted from the original JSON result sets returned by Meetup.com. As an intermediate format .csv files are created as part of this workflow for the different data entities containing all data of interest.
Please note that during the transformation process new IDs are created and assigned to the original data. This is due to the fact that the data type for IDs generated by Meetup.com for their data is not consistent. It is mostly numeric but can be alphanumeric as well even for data of the same entity. Since Property Graph requires to have numeric IDs only they are generated by the R script.

### Prepare the work environment
```{r echo=TRUE}
setwd('~/Documents/Meetup/scripts')
rm(list = ls())
```
  
### Load required packages
Make sure to install these packages before. In Big Data Lite VM simply edit /home/oracle/src/thirdparty/rstudio.sh in the *install_extra* section to add missing packages and then run the Shell script.
```{r echo=TRUE}
library('readr')
library('dplyr')
library('stringr')
library('jsonlite')
library('anytime')
library('tidyr')
```
  
### Helper functions
```{r echo=TRUE}
## Encoding of special characters (Documentation chapter 5.13.4 Encoding Special Characters)
replace_special_chars <- function(col){
  str_replace_all(col,c("%"="%25"," "="%20",","="%2C","\t"="%09","\n"="%0A","\r"="%0D"))
}
```
  
### Set global variables
Note: To retrieve data from Meetup.com you´ll need a user profile and an API Key. The latter you can get via https://secure.meetup.com/meetup_api/key/ and is related to your user profile (location).
Please copy your key(s) as well as the country code and city name into the matrix  below. You can insert as many rows as you have keys but need to adapt *nrows* accordingly. The number and order of columns needs to stay as given below.
```{r echo=TRUE}
## Meetup REST API keys for 4 user profiles covering following cities of interest: ##   Berlin/DE, Munich/DE, Hamburg/DE and Copenhagen/DK
api_keys <- 
  matrix(
    c(
      "key=xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx","country=DE","city=Berlin",
      "key=yyyyyyyyyyyyyyyyyyyyyyyyyyyyyyy","country=DE","city=München",
      "key=zzzzzzzzzzzzzzzzzzzzzzzzzzzz","country=DK","city=Copenhagen"),
    nrow=3,
    ncol=3,
    byrow = TRUE)
```
```{r echo=TRUE}
## Data types used in Oracle´s Flat File format for Property Graph
str_dt=1
int_dt=2
flt_dt=3
dbl_dt=4
date_dt=5
lint_dt=7
sint=8

## Set the minimum number of members in a Meetup group 
member_threshold=400

## Number of records returned by a request (REST API  call) is limited to 200
page_threshold=200

## Variables used to compute surrogate IDs that are used to replace Meetup IDs
seq_start=1
seq_last=1
seq_end=0
seq_offset=0
```

### Target Data Structures  
- Nodes: "vertex_ID","key_name","value_type","strValue","numValue","datValue"     
- Edges: "edge_ID","source_ID","dest_ID","e_label","key_name","value_type","strValue","numValue","datValue"    

### Retrieve and transform source data from Meetup.com

#### 1. CITIES
Sample request: https://api.meetup.com/2/cities?key=506c1916524f6d3a6c782432645f5eb&country=DE&only=id,country,city,lat,lon,ranking,member_count
```{r echo=TRUE}
## Initialize pages
pages <- list()
p=1

## Send requests using the offset URL query parameter as long as results are returned
for (k in 1:nrow(api_keys)) {
  baseurl <- "https://api.meetup.com/2/cities?"
  query_params <- "&only=id,country,city,lat,lon,ranking,member_count" 
  url <- URLencode(paste0(baseurl,api_keys[k,1],"&",api_keys[k,2],query_params))
  
  total_count <- fromJSON(url)$meta$total_count
  offset <- round(total_count/page_threshold)
  
  for(i in 0:offset) {
    url2 <- URLencode(paste0(url, "&offset=", i))
    meetup_cities <- fromJSON(url2, flatten=TRUE)
    message("Retrieving page ", i)
    Sys.sleep(3)
    pages[[p]] <- meetup_cities$results
    p=p+1
  }
}

## Bind pages but avoid empty pages
meetup_cities <- rbind_pages(pages[sapply(pages, length)>0])

## Eliminate duplicates
meetup_cities <- unique(meetup_cities)

## Check data
names(meetup_cities)
nrow(meetup_cities)
dim(meetup_cities)
head(meetup_cities)
```

```{r echo=TRUE}
## Extract only cities with member_count >= member_threshold
meetup_cities_subset <- subset(meetup_cities, member_count >=  member_threshold)

## Export data into .csv (without observation number)
file_name_base = "cities"
file_name = paste("../data/",file_name_base,".csv",sep = "")
write.csv(meetup_cities_subset, file_name, row.names = FALSE, fileEncoding = "UTF-8", quote = TRUE)

## Read data from .csv
cities <- 
  read_csv(
    file_name,
    trim_ws = TRUE,
    col_names = names(meetup_cities_subset),
    skip=1)

## Check data
str(cities)

## Add column with sequence number to be used as VID (node identifier)
seq_offset <- nrow(cities)
seq_start <- seq_last
seq_end <- seq_start + seq_offset - 1
cities$VID <- c(seq.int(from=seq_start,to=seq_end,by=1))
seq_last <- seq_end + 1

## Reshape the data (leaving out original Meetup IDs), pushing columns into rows for the various types of information to store about each node and edge.

##   Create a dataframe containing all nodes
nodes.cities.type <- 
  cities %>% 
  select(VID) %>% 
  mutate(key='type') %>% 
  mutate(datatype=str_dt) %>% 
  mutate(strval = 'City') %>% 
  mutate(numval=NA) %>% 
  mutate(datval=NA)
nodes.cities.type

nodes.cities.city <- 
  cities %>% 
  select(VID) %>% 
  mutate(key='city_name') %>% 
  mutate(datatype=str_dt) %>% 
  bind_cols(select(cities,c(city))) %>% rename(strval='city') %>% 
  mutate(numval=NA) %>% 
  mutate(datval=NA)
## Remove empty values
nodes.cities.city <- nodes.cities.city[!is.na(nodes.cities.city$strval),]
nodes.cities.city

nodes.cities.country <- 
  cities %>% 
  select(VID) %>% 
  mutate(key='city_country') %>% 
  mutate(datatype=str_dt) %>% 
  bind_cols(select(cities,c(country))) %>% rename(strval='country') %>% 
  mutate(numval=NA) %>% 
  mutate(datval=NA)
## Remove empty values
nodes.cities.country <- nodes.cities.country[!is.na(nodes.cities.country$strval),]
nodes.cities.country

nodes.cities.lon <- 
  cities %>% 
  select(VID) %>% 
  mutate(key='city_lon') %>% 
  mutate(datatype=dbl_dt) %>% 
  mutate(strval=NA) %>% 
  bind_cols(select(cities,c(lon))) %>% rename(numval='lon') %>% 
  mutate(datval=NA)
## Remove empty values
nodes.cities.lon <- nodes.cities.lon[!is.na(nodes.cities.lon$numval),]
nodes.cities.lon$numval <- round(nodes.cities.lon$numval,2)
nodes.cities.lon

nodes.cities.lat <- 
  cities %>% 
  select(VID) %>% 
  mutate(key='city_lat') %>% 
  mutate(datatype=dbl_dt) %>% 
  mutate(strval=NA) %>% 
  bind_cols(select(cities,c(lat))) %>% rename(numval='lat') %>% 
  mutate(datval=NA)
## Remove empty values
nodes.cities.lat <- nodes.cities.lat[!is.na(nodes.cities.lat$numval),]
nodes.cities.lat$numval <- round(nodes.cities.lat$numval,2)
nodes.cities.lat

nodes.cities.ranking <- 
  cities %>% 
  select(VID) %>% 
  mutate(key='city_ranking') %>% 
  mutate(datatype=int_dt) %>% 
  mutate(strval=NA) %>% 
  bind_cols(select(cities,c(ranking))) %>% rename(numval='ranking') %>% 
  mutate(datval=NA)
## Remove empty values
nodes.cities.ranking <- nodes.cities.ranking[!is.na(nodes.cities.ranking$numval),]
nodes.cities.ranking$numval <- as.integer(nodes.cities.ranking$numval)
nodes.cities.ranking

nodes.cities.member.count <- 
  cities %>% 
  select(VID) %>% 
  mutate(key='city_member_count') %>% 
  mutate(datatype=int_dt) %>% 
  mutate(strval=NA) %>% 
  bind_cols(select(cities,c(member_count))) %>% rename(numval='member_count') %>% 
  mutate(datval=NA)
## Remove empty values
nodes.cities.member.count <- nodes.cities.member.count[!is.na(nodes.cities.member.count$numval),]
nodes.cities.member.count$numval <- as.integer(nodes.cities.member.count$numval)
nodes.cities.member.count

## Join all CITIES nodes together
nodes.cities <-
  bind_rows(
    nodes.cities.type,
    nodes.cities.city,
    nodes.cities.country,
    nodes.cities.lon,
    nodes.cities.lat,
    nodes.cities.ranking,
    nodes.cities.member.count)

## Eliminate duplicates (just to be safe)
nodes.cities <- unique(nodes.cities)

View(nodes.cities)

## Edges:
##   Create a dataframe containing all edges

## No (outgoing) edges for cities

Sys.sleep(10)
```
  
#### 2. CATEGORIES
Sample request: https://api.meetup.com/2/categories?key=506c1916524f6d3a6c782432645f5eb&country=DE
```{r echo=TRUE}
## Initialize pages
pages <- list()
p=1

## Send requests using the offset URL query parameter as long as results are returned
for (key in api_keys[1,1]) {
  baseurl <- "https://api.meetup.com/2/categories?"
  url <- URLencode(paste0(baseurl,api_keys[k,1],"&",api_keys[k,2]))
  
  total_count <- fromJSON(url)$meta$total_count
  offset <- round(total_count/page_threshold)
  
  for(i in 0:offset) {
    url2 <- URLencode(paste0(url, "&offset=", i))
    meetup_categories <- fromJSON(url2, flatten=TRUE)
    message("Retrieving page ", i)
    Sys.sleep(2)
    pages[[p]] <- meetup_categories$results
    p=p+1
  }
}

## Bind pages but avoid empty pages
meetup_categories <- rbind_pages(pages[sapply(pages, length)>0])

## Eliminate duplicates
meetup_categories <- unique(meetup_categories)

names(meetup_categories)
nrow(meetup_categories)
dim(meetup_categories)
head(meetup_categories)
```

```{r echo=TRUE}
# Export data into .csv (without observation number)
file_name_base = "categories"
file_name = paste("../data/",file_name_base,".csv",sep = "")
write.csv(meetup_categories, file_name, row.names = FALSE, fileEncoding = "UTF-8", quote = TRUE)

## Read data from .csv
categories <- 
  read_csv(
    file_name,
    trim_ws = TRUE,
    col_names = names(meetup_categories),
    skip=1)

## Check data
str(categories)

## Add column with sequence number to be used as VID (node identifier)
seq_offset <- nrow(categories)
seq_start <- seq_last
seq_end <- seq_start + seq_offset - 1
categories$VID <- c(seq.int(from=seq_start,to=seq_end,by=1))
seq_last <- seq_end + 1

## Reshape the data (leaving out original Meetup IDs), pushing columns into rows for the various types of information to store about each node and edge.

## Nodes:
##   Create a dataframe containing all nodes
nodes.categories.type <- 
  categories %>% 
  select(VID) %>% 
  mutate(key='type') %>% 
  mutate(datatype=str_dt) %>% 
  mutate(strval = 'Category') %>% 
  mutate(numval=NA) %>% 
  mutate(datval=NA)
nodes.categories.type

nodes.categories.name <- 
  categories %>% 
  select(VID) %>% 
  mutate(key='category_name') %>% 
  mutate(datatype=str_dt) %>% 
  bind_cols(select(categories,c(name))) %>% rename(strval='name') %>% 
  mutate(numval=NA) %>% 
  mutate(datval=NA)
## Remove empty values
nodes.categories.name <- nodes.categories.name[!is.na(nodes.categories.name$strval),]
nodes.categories.name

nodes.categories.shortname <- 
  categories %>% 
  select(VID) %>% 
  mutate(key='category_shortname') %>% 
  mutate(datatype=str_dt) %>% 
  bind_cols(select(categories,c(shortname))) %>% rename(strval='shortname') %>% 
  mutate(numval=NA) %>% 
  mutate(datval=NA)
## Remove empty values
nodes.categories.shortname <- nodes.categories.shortname[!is.na(nodes.categories.shortname$strval),]
nodes.categories.shortname

## Join all categories nodes together
nodes.categories <-
  bind_rows(
    nodes.categories.type,
    nodes.categories.name,
    nodes.categories.shortname)

## Eliminate duplicates (just to be safe)
nodes.categories <- unique(nodes.categories)

View(nodes.categories)

## Edges:
##   Create a dataframe containing all edges

## No (outgoing) edges for categories

Sys.sleep(10)
```
  
#### 3. GROUPS
Sample request: https://api.meetup.com/2/groups?key=506c1916524f6d3a6c782432645f5eb&country=DE&category_id=34&city=Berlin&page=200&only=score,id,name,status,link,created,city,country,state,urlname,join_mode,visibility,members,who,category.id
```{r echo=TRUE}
pages <- list()
p=1

## Send requests using the offset URL query parameter as long as results are returned
for (k in 1:nrow(api_keys)) {
  baseurl <- "https://api.meetup.com/2/groups?"
  query_params <- "&category_id=34&page=200&only=score,id,name,status,link,created,city,country,state,urlname,join_mode,visibility,members,who,category.id" 
  url <- URLencode(paste0(baseurl,api_keys[k,1],"&",api_keys[k,2],"&",api_keys[k,3],query_params))

  total_count <- fromJSON(url)$meta$total_count
  total_count
  offset <- round(total_count/page_threshold)

  for(i in 0:offset) {
    url2 <- URLencode(paste0(url, "&offset=", i))
    meetup_groups <- fromJSON(url2, flatten=TRUE)
    message("Retrieving page ", i)
    Sys.sleep(2)
    pages[[p]] <- meetup_groups$results
	  p=p+1
  }
}
  
## Bind pages but avoid empty pages
meetup_groups <- rbind_pages(pages[sapply(pages, length)>0])

## Eliminate duplicates
meetup_groups <- unique(meetup_groups)

## Check data
names(meetup_groups)
nrow(meetup_groups)
dim(meetup_groups)
head(meetup_groups)
```

```{r echo=TRUE}
## Extract only groups with members >= threshold
meetup_groups_subset <- subset(meetup_groups, members >= member_threshold)

## Export data into .csv (without observation number)
file_name_base = "groups"
file_name = paste("../data/",file_name_base,".csv",sep = "")
write.csv(meetup_groups_subset, file_name, row.names = FALSE, fileEncoding = "UTF-8", quote = TRUE)
groups <- 
  read_csv(
    file_name,
    trim_ws = TRUE,
    col_names = names(meetup_groups_subset),
    skip=1)

## Convert creation date from EpochTimeInMillies to Date
groups$created <- paste0(anydate((groups$created)/1000),'T00:00:00.000+01:00')

## Check data
str(groups)

## Add column with sequence number to be used as VID (node identifier)
seq_offset <- nrow(groups)
seq_start <- seq_last
seq_end <- seq_start + seq_offset - 1
groups$VID <- c(seq.int(from=seq_start,to=seq_end,by=1))
seq_last <- seq_end + 1

## Reshape the data (leaving out original Meetup IDs), pushing columns into rows for the various types of information to store about each node and edge.

## Nodes:
##   Create a dataframe containing all nodes
nodes.groups.type <- 
  groups %>% 
  select(VID) %>% 
  mutate(key='type') %>% 
  mutate(datatype=str_dt) %>% 
  mutate(strval = 'Group') %>% 
  mutate(numval=NA) %>% 
  mutate(datval=NA)
nodes.groups.type

nodes.groups.visibility <- 
  groups %>% 
  select(VID) %>% 
  mutate(key='group_visibility') %>% 
  mutate(datatype=str_dt) %>% 
  bind_cols(select(groups,c(visibility))) %>% rename(strval='visibility') %>% 
  mutate(numval=NA) %>% 
  mutate(datval=NA)
## Remove empty values
nodes.groups.visibility <- nodes.groups.visibility[!is.na(nodes.groups.visibility$strval),]
nodes.groups.visibility

nodes.groups.country <- 
  groups %>% 
  select(VID) %>% 
  mutate(key='group_country') %>% 
  mutate(datatype=str_dt) %>% 
  bind_cols(select(groups,c(country))) %>% rename(strval='country') %>% 
  mutate(numval=NA) %>% 
  mutate(datval=NA)
## Remove empty values
nodes.groups.country <- nodes.groups.country[!is.na(nodes.groups.country$strval),]
nodes.groups.country

nodes.groups.created <- 
  groups %>% 
  select(VID) %>% 
  mutate(key='group_created') %>% 
  mutate(datatype=date_dt) %>% 
  mutate(strval=NA) %>% 
  mutate(numval=NA) %>% 
  bind_cols(select(groups,c(created))) %>% rename(datval='created')
## Remove empty values
nodes.groups.created <- nodes.groups.created[!is.na(nodes.groups.created$datval),]
nodes.groups.created

nodes.groups.members <- 
  groups %>% 
  select(VID) %>% 
  mutate(key='group_members') %>% 
  mutate(datatype=int_dt) %>% 
  mutate(strval=NA) %>% 
  bind_cols(select(groups,c(members))) %>% rename(numval='members') %>% 
  mutate(datval=NA)
## Remove empty values
nodes.groups.members <- nodes.groups.members[!is.na(nodes.groups.members$numval),]
nodes.groups.members$numval <- as.integer(nodes.groups.members$numval)
nodes.groups.members

nodes.groups.link <- 
  groups %>% 
  select(VID) %>% 
  mutate(key='group_link') %>% 
  mutate(datatype=str_dt) %>% 
  bind_cols(select(groups,c(link))) %>% rename(strval='link') %>% 
  mutate(numval=NA) %>% 
  mutate(datval=NA)
## Remove empty values
nodes.groups.link <- nodes.groups.link[!is.na(nodes.groups.link$strval),]
nodes.groups.link

nodes.groups.join.mode <- 
  groups %>% 
  select(VID) %>% 
  mutate(key='group_join_mode') %>% 
  mutate(datatype=str_dt) %>% 
  bind_cols(select(groups,c(join_mode))) %>% rename(strval='join_mode') %>% 
  mutate(numval=NA) %>% 
  mutate(datval=NA)
## Remove empty values
nodes.groups.join.mode <- nodes.groups.join.mode[!is.na(nodes.groups.join.mode$strval),]
nodes.groups.join.mode

nodes.groups.name <- 
  groups %>% 
  select(VID) %>% 
  mutate(key='group_name') %>% 
  mutate(datatype=str_dt) %>% 
  bind_cols(select(groups,c(name))) %>% rename(strval='name') %>% 
  mutate(numval=NA) %>% 
  mutate(datval=NA)
## Remove empty values
nodes.groups.name <- nodes.groups.name[!is.na(nodes.groups.name$strval),]
nodes.groups.name

nodes.groups.urlname <- 
  groups %>% 
  select(VID) %>% 
  mutate(key='group_urlname') %>% 
  mutate(datatype=str_dt) %>% 
  bind_cols(select(groups,c(urlname))) %>% rename(strval='urlname') %>% 
  mutate(numval=NA) %>% 
  mutate(datval=NA)
## Remove empty values
nodes.groups.urlname <- nodes.groups.urlname[!is.na(nodes.groups.urlname$strval),]
nodes.groups.urlname

nodes.groups.who <- 
  groups %>% 
  select(VID) %>% 
  mutate(key='group_who') %>% 
  mutate(datatype=str_dt) %>% 
  bind_cols(select(groups,c(who))) %>% rename(strval='who') %>% 
  mutate(numval=NA) %>% 
  mutate(datval=NA)
## Remove empty values
nodes.groups.who <- nodes.groups.who[!is.na(nodes.groups.who$strval),]
nodes.groups.who

## Join all GROUPS nodes together
nodes.groups <-
  bind_rows(
    nodes.groups.type,
    nodes.groups.visibility,
    nodes.groups.country,
    nodes.groups.created,
    nodes.groups.members,
    nodes.groups.link,
    nodes.groups.join.mode,
    nodes.groups.name,
    nodes.groups.urlname,
  	nodes.groups.who)

## Eliminate duplicates (just to be safe)
nodes.groups <- unique(nodes.groups)
  
View(nodes.groups)

## Edges:
##   Create a dataframe containing all edges

##   Edge: Group - located_in - City
groups_rel_cities <- merge(x = groups, y = cities, by = "city")
groups_rel_cities <- groups_rel_cities[,c("VID.x","VID.y")]

seq_offset <- nrow(groups_rel_cities)
seq_start <- seq_last
seq_end <- seq_start + seq_offset - 1
groups_rel_cities$EID <- c(seq.int(from=seq_start,to=seq_end,by=1)) 
seq_last <- seq_end + 1

edges.groups.city <- 
  groups_rel_cities %>% 
  select(EID) %>% 
  bind_cols(select(groups_rel_cities,c(VID.x))) %>% rename(node_1='VID.x') %>% 
  bind_cols(select(groups_rel_cities,c(VID.y))) %>% rename(node_2='VID.y') %>% 
  mutate(label='is_located_in') %>% 
  mutate(key='%20') %>%
  mutate(datatype=NA) %>%
  mutate(strval=NA) %>%
  mutate(numval=NA) %>%
  mutate(datval=NA)
edges.groups.city					 

##   Edge: Category - is_assigned_to - Group
groups_rel_categories <- merge(x = groups, y = categories, by.x = "category.id", by.y = "id")
groups_rel_categories <- groups_rel_categories[,c("VID.x","VID.y")]

seq_offset <- nrow(groups_rel_categories)
seq_start <- seq_last
seq_end <- seq_start + seq_offset - 1
groups_rel_categories$EID <- c(seq.int(from=seq_start,to=seq_end,by=1)) 
seq_last <- seq_end + 1

edges.groups.category <- 
  groups_rel_categories %>% 
  select(EID) %>% 
  bind_cols(select(groups_rel_categories,c(VID.y))) %>% rename(node_1='VID.y') %>% 
  bind_cols(select(groups_rel_categories,c(VID.x))) %>% rename(node_2='VID.x') %>% 
  mutate(label='is_assigned_to') %>% 
  mutate(key='%20') %>%
  mutate(datatype=NA) %>%
  mutate(strval=NA) %>%
  mutate(numval=NA) %>%
  mutate(datval=NA)
edges.groups.category

## Join all GROUPS edges together
edges.groups <-
  bind_rows(
    edges.groups.city,
    edges.groups.category)

## Eliminate duplicates (just to be safe)
edges.groups <- unique(edges.groups)
  
View(edges.groups)

Sys.sleep(10)
```
  
#### 4. MEMBERS
Note: Consider only those members that are group organizers  
Sample request: https://api.meetup.com/2/groups?key=506c1916524f6d3a6c782432645f5eb&country=DE&category_id=34&city=Berlin&category_id=34&page=200&only=id,organizer,members
```{r echo=TRUE}
pages <- list()
p=1

## Send requests using the offset URL query parameter as long as results are returned
for (k in 1:nrow(api_keys)) {
  baseurl <- "https://api.meetup.com/2/groups?"
  query_params <- "&category_id=34&page=200&only=id,organizer,members" 
  url <- URLencode(paste0(baseurl,api_keys[k,1],"&",api_keys[k,2],"&",api_keys[k,3],query_params))

  total_count <- fromJSON(url)$meta$total_count
  total_count
  offset <- round(total_count/page_threshold)

  for(i in 0:offset) {
    url2 <- URLencode(paste0(url, "&offset=", i))
    meetup_organizers <- fromJSON(url2, flatten=TRUE)
    message("Retrieving page ", i)
    Sys.sleep(2)
    pages[[p]] <- meetup_organizers$results
	p=p+1
  }
}

## Bind pages but avoid empty pages
meetup_organizers <- rbind_pages(pages[sapply(pages, length)>0])

## Eliminate duplicates
meetup_organizers <- unique(meetup_organizers)

## Check data
names(meetup_organizers)
nrow(meetup_organizers)
dim(meetup_organizers)
head(meetup_organizers)
```

```{r echo=TRUE}
meetup_organizers <- meetup_organizers[,c("id","organizer.member_id","organizer.name","members")]
names(meetup_organizers) <- c("group_id","id","name","members")

## Extract only organizers of groups with members >= threshold. Remove rows with id == 'NA'.
meetup_organizers_subset <- subset(meetup_organizers, members >= member_threshold && !is.na(id))

## Export data into .csv without observation number
file_name_base = "members"
file_name = paste("../data/",file_name_base,".csv",sep = "")

write.csv(meetup_organizers_subset, file_name, row.names = FALSE, fileEncoding = "UTF-8", quote = TRUE)

members <- 
  read_csv(
    file_name,
    trim_ws = TRUE,
    col_names = names(meetup_organizers_subset),
    skip=1)

## Extract member id and name only and remove duplicates
organizers <- unique(members[2:3])

## Check data
str(organizers)

## Add column with sequence number to be used as VID
seq_offset <- nrow(organizers)
seq_start <- seq_last
seq_end <- seq_start + seq_offset - 1
organizers$VID <- c(seq.int(from=seq_start,to=seq_end,by=1))
seq_last <- seq_end + 1

## Reshape the data (leaving out original Meetup IDs), pushing columns into rows for the various types of information to store about each node and edge.

##   Create a dataframe containing all nodes
nodes.members.type <- 
  organizers %>% 
  select(VID) %>% 
  mutate(key='type') %>% 
  mutate(datatype=str_dt) %>% 
  mutate(strval = 'Member') %>% 
  mutate(numval=NA) %>% 
  mutate(datval=NA)
nodes.members.type

nodes.members.name <- 
  organizers %>% 
  select(VID) %>% 
  mutate(key='member_name') %>% 
  mutate(datatype=str_dt) %>% 
  bind_cols(select(organizers,c(name))) %>% rename(strval='name') %>% 
  mutate(numval=NA) %>% 
  mutate(datval=NA)
## Remove empty values
nodes.members.name <- nodes.members.name[!is.na(nodes.members.name$strval),]
nodes.members.name

## Join all MEMBERS nodes together
nodes.members <-
  bind_rows(
    nodes.members.type, 
    nodes.members.name)

## Eliminate duplicates (just to be safe)
nodes.members <- unique(nodes.members)

View(nodes.members)

## Edges:
##   Create a dataframe containing all edges

##   Edge: Member - is_organizer_of - Group

## Join different data frames
members_rel_organizers <- merge(x = members, y = organizers, by.x = "id", by.y = "id")
organizers_rel_groups <- merge(x = members_rel_organizers, y = groups, by.x = "group_id", by.y = "id")
organizers_rel_groups <- organizers_rel_groups[,c("VID.x","VID.y")]

seq_offset <- nrow(organizers_rel_groups)
seq_start <- seq_last
seq_end <- seq_start + seq_offset - 1
organizers_rel_groups$EID <- c(seq.int(from=seq_start,to=seq_end,by=1)) 
seq_last <- seq_end + 1

edges.members.group <- 
  organizers_rel_groups %>% 
  select(EID) %>% 
  bind_cols(select(organizers_rel_groups,c(VID.x))) %>% rename(node_1='VID.x') %>% 
  bind_cols(select(organizers_rel_groups,c(VID.y))) %>% rename(node_2='VID.y') %>% 
  mutate(label='is_organizer_of') %>% 
  mutate(key='%20') %>%
  mutate(datatype=NA) %>%
  mutate(strval=NA) %>%
  mutate(numval=NA) %>%
  mutate(datval=NA)
edges.members.group

## Join all MEMBERS edges together
edges.members <-
  bind_rows(edges.members.group)

## Eliminate duplicates (just to be safe)
edges.members <- unique(edges.members)
  
View(edges.members)

Sys.sleep(10)
```
  
#### 5. EVENTS
Sample request: https://api.meetup.com/2/events?key=506c1916524f6d3a6c782432645f5eb&country=DE&category=34&status=past&page=200&only=visibility,waitlist_count,rating,yes_rsvp_count,id,time,duration,status,rsvp_limit,maybe_rsvp_count,group.id
```{r echo=TRUE}
pages <- list()
p=1

## Send requests using the offset URL query parameter as long as results are returned
##   !! Set some sleep time in between requests to avoid HTTP 429 (Too many requests)
for (k in 1:nrow(api_keys)) {
  baseurl <- "https://api.meetup.com/2/events?"
  query_params <- "&category=34&status=past&page=200&only=visibility,waitlist_count,rating,yes_rsvp_count,id,time,duration,status,rsvp_limit,maybe_rsvp_count,group.id" 
  url <- URLencode(paste0(baseurl,api_keys[k,1],"&",api_keys[k,2],query_params))
  
  ## Split country code and city name from matrix
  co <- word(api_keys[k, 2], 2, sep="=")
  ci <- word(api_keys[k, 3], 2, sep="=")
  
  ## Retrieve tech groups in selected country && city only
  groups_subset <- subset(groups,country==co & city==ci)
  len <- nrow(groups_subset)

  ## Iterate over groups extracted previously (assign group_urlname as query parameter to URL)
  for (j in 1:len) {
    group_urlname <- groups_subset$urlname[j]
    url_with_group_urlname <- URLencode(paste0(url, "&group_urlname=", group_urlname))
    total_count <- fromJSON(url_with_group_urlname)$meta$total_count
    # print(total_count)

    if (total_count >= 1) {
      offset <- round(total_count/page_threshold)

      for(i in 0:offset) {
	    url2 <- URLencode(paste0(url_with_group_urlname, "&offset=", i))
	    meetup_events <- fromJSON(url2, flatten=TRUE)
	    message("Retrieving page ", i)
	    Sys.sleep(3)
	    pages[[p]] <- meetup_events$results
	    p=p+1
	  }
      }
  } 
} 

## Bind pages but avoid empty pages
meetup_events <- rbind_pages(pages[sapply(pages, length)>0])

## Eliminate duplicates
meetup_events <- unique(meetup_events)

## Check data
names(meetup_events)
nrow(meetup_events)
dim(meetup_events)
head(meetup_events)
```

```{r echo=TRUE}
## Export data into .csv (without observation number)
file_name_base = "events"
file_name = paste("../data/",file_name_base,".csv",sep = "")
write.csv(meetup_events, file_name, row.names = FALSE, fileEncoding = "UTF-8", quote = TRUE)

events <- 
  read_csv(
    file_name,
    trim_ws = TRUE,
    col_names = names(meetup_events),
    skip=1)

## Convert creation date from EpochTimeInMillies to Date. Store as Java SimpleDateFormat (Ex. 2017-03-27T00:00:00.000+01:00)
events$time <- paste0(anydate((events$time)/1000),'T00:00:00.000+01:00')

## Check data
str(events)

## Add column with sequence number to be used as VID (node identifier)
seq_offset <- nrow(events)
seq_start <- seq_last
seq_end <- seq_start + seq_offset - 1
events$VID <- c(seq.int(from=seq_start,to=seq_end,by=1))
seq_last <- seq_end + 1

## Reshape the data (leaving out original Meetup IDs), pushing columns into rows for the various types of information to store about each node and edge.

## Nodes:
##   Create a dataframe containing all event nodes
nodes.events.type <-
  events %>% 
  select(VID) %>% 
  mutate(key='type') %>% 
  mutate(datatype=str_dt) %>% 
  mutate(strval = 'Event') %>% 
  mutate(numval=NA) %>% 
  mutate(datval=NA)
nodes.events.type

nodes.events.visibility <- 
  events %>% 
  select(VID) %>% 
  mutate(key='event_visibility') %>% 
  mutate(datatype=str_dt) %>% 
  bind_cols(select(events,c(visibility))) %>% rename(strval='visibility') %>% 
  mutate(numval=NA) %>% 
  mutate(datval=NA)
## Remove empty values
nodes.events.visibility <- nodes.events.visibility[!is.na(nodes.events.visibility$strval),]
nodes.events.visibility

nodes.events.waitlist.count <- 
  events %>% 
  select(VID) %>% 
  mutate(key='event_waitlist_count') %>% 
  mutate(datatype=int_dt) %>% 
  mutate(strval=NA) %>% 
  bind_cols(select(events,c(waitlist_count))) %>% rename(numval='waitlist_count') %>% 
  mutate(datval=NA)
## Remove empty values
nodes.events.waitlist.count <- nodes.events.waitlist.count[!is.na(nodes.events.waitlist.count$numval),]
nodes.events.waitlist.count$numval <- as.integer(nodes.events.waitlist.count$numval)
nodes.events.waitlist.count

nodes.events.maybe.rsvp.count <- 
  events %>% 
  select(VID) %>% 
  mutate(key='event_maybe_rsvp_count') %>% 
  mutate(datatype=int_dt) %>% 
  mutate(strval=NA) %>% 
  bind_cols(select(events,c(maybe_rsvp_count))) %>% rename(numval='maybe_rsvp_count') %>% 
  mutate(datval=NA)
## Remove empty values
nodes.events.maybe.rsvp.count <- nodes.events.maybe.rsvp.count[!is.na(nodes.events.maybe.rsvp.count$numval),]
nodes.events.maybe.rsvp.count$numval <- as.integer(nodes.events.maybe.rsvp.count$numval)
nodes.events.maybe.rsvp.count

nodes.events.yes.rsvp.count <- 
  events %>% 
  select(VID) %>% 
  mutate(key='event_yes_rsvp_count') %>% 
  mutate(datatype=int_dt) %>% 
  mutate(strval=NA) %>% 
  bind_cols(select(events,c(yes_rsvp_count))) %>% rename(numval='yes_rsvp_count') %>% 
  mutate(datval=NA)
## Remove empty values
nodes.events.yes.rsvp.count <- nodes.events.yes.rsvp.count[!is.na(nodes.events.yes.rsvp.count$numval),]
nodes.events.yes.rsvp.count$numval <- as.integer(nodes.events.yes.rsvp.count$numval)
nodes.events.yes.rsvp.count

nodes.events.rsvp.limit <- 
  events %>% 
  select(VID) %>% 
  mutate(key='event_rsvp_limit') %>% 
  mutate(datatype=int_dt) %>% 
  mutate(strval=NA) %>% 
  bind_cols(select(events,c(rsvp_limit))) %>% rename(numval='rsvp_limit') %>% 
  mutate(datval=NA)
## Remove empty values
nodes.events.rsvp.limit <- nodes.events.rsvp.limit[!is.na(nodes.events.rsvp.limit$numval),]
nodes.events.rsvp.limit$numval <- as.integer(nodes.events.rsvp.limit$numval)
nodes.events.rsvp.limit

nodes.events.time <- 
  events %>% select(VID) %>% 
  mutate(key='event_date') %>% 
  mutate(datatype=date_dt) %>% 
  mutate(strval=NA) %>% 
  mutate(numval=NA) %>% 
  bind_cols(select(events,c(time))) %>% rename(datval='time')
## Remove empty values
nodes.events.time <- nodes.events.time[!is.na(nodes.events.time$datval),]
nodes.events.time

nodes.events.rating.count <- 
  events %>% 
  select(VID) %>% 
  mutate(key='event_rating_count') %>% 
  mutate(datatype=int_dt) %>% 
  mutate(strval=NA) %>% 
  bind_cols(select(events,c(rating.count))) %>% rename(numval='rating.count') %>% 
  mutate(datval=NA)
## Remove empty values
nodes.events.rating.count <- nodes.events.rating.count[!is.na(nodes.events.rating.count$numval),]
nodes.events.rating.count$numval <- as.integer(nodes.events.rating.count$numval)
nodes.events.rating.count

nodes.events.rating.average <- 
  events %>% 
  select(VID) %>% 
  mutate(key='event_rating_average') %>% 
  mutate(datatype=dbl_dt) %>% 
  mutate(strval=NA) %>% 
  bind_cols(select(events,c(rating.average))) %>% rename(numval='rating.average') %>% 
  mutate(datval=NA)
## Remove empty values
nodes.events.rating.average <- nodes.events.rating.average[!is.na(nodes.events.rating.average$numval),]
nodes.events.rating.average$numval <- round(nodes.events.rating.average$numval,2)
nodes.events.rating.average

nodes.events.status <- 
  events %>% 
  select(VID) %>% 
  mutate(key='event_status') %>% 
  mutate(datatype=str_dt) %>% 
  bind_cols(select(events,c(status))) %>% rename(strval='status') %>% 
  mutate(numval=NA) %>% 
  mutate(datval=NA)
## Remove empty values
nodes.events.status <- nodes.events.status[!is.na(nodes.events.status$numval),]
nodes.events.status

## Join all EVENTS nodes together
nodes.events <-
  bind_rows(
    nodes.events.type, 
	  nodes.events.visibility,
	  nodes.events.waitlist.count,
	  nodes.events.maybe.rsvp.count,
	  nodes.events.yes.rsvp.count,
	  nodes.events.rsvp.limit,
	  nodes.events.time,
	  nodes.events.rating.count,
	  nodes.events.rating.average,
	  nodes.events.status)

## Eliminate duplicates (just to be safe)
nodes.events <- unique(nodes.events)

View(nodes.events)

## Edges:
##   Create a dataframe containing all edges

##   Edge: Event - is_organized_by - Group
events_rel_groups <- merge(x = events, y = groups, by.x = "group.id", by.y = "id")
events_rel_groups <- events_rel_groups[,c("VID.x","VID.y")]

seq_offset <- nrow(events_rel_groups)
seq_start <- seq_last
seq_end <- seq_start + seq_offset - 1
events_rel_groups$EID <- c(seq.int(from=seq_start,to=seq_end,by=1)) 
seq_last <- seq_end + 1

edges.events.group <- 
  events_rel_groups %>% 
  select(EID) %>% 
  bind_cols(select(events_rel_groups,c(VID.x))) %>% rename(node_1='VID.x') %>% 
  bind_cols(select(events_rel_groups,c(VID.y))) %>% rename(node_2='VID.y') %>% 
  mutate(label='is_organized_by') %>% 
  mutate(key='%20') %>%
  mutate(datatype=NA) %>%
  mutate(strval=NA) %>%
  mutate(numval=NA) %>%
  mutate(datval=NA)
edges.events.group

## Join all EVENTS edges together
edges.events <-
  bind_rows(edges.events.group)

# Remove dulicates if there are
edges.events <- unique(edges.events)
  
View(edges.events)

Sys.sleep(10)
```
  
#### 6. TOPICS
Sample request: https://api.meetup.com/2/groups?key=506c1916524f6d3a6c782432645f5eb&country=DE&city=Berlin&category_id=34&page=200&only=id,topics
```{r echo=TRUE}
pages <- list()
p=1

## Send requests using the offset URL query parameter as long as results are returned
for (k in 1:nrow(api_keys)) {
  baseurl <- "https://api.meetup.com/2/groups?"
  query_params <- "&category_id=34&page=200&only=id,topics" 
  url <- URLencode(paste0(baseurl,api_keys[k,1],"&",api_keys[k,2],"&",api_keys[k,3],query_params))

  total_count <- fromJSON(url)$meta$total_count
  total_count
  offset <- round(total_count/page_threshold)

  for(i in 0:offset) {
    url2 <- URLencode(paste0(url, "&offset=", i))
    meetup_topics <- fromJSON(url2, flatten=TRUE)
    message("Retrieving page ", i)
    Sys.sleep(1)
    pages[[p]] <- meetup_topics$results
	p=p+1
  }
}

## Bind pages but avoid empty pages
meetup_topics <- rbind_pages(pages[sapply(pages, length)>0])

## Eliminate duplicates
meetup_topics <- unique(meetup_topics)

## Check data
names(meetup_topics)
nrow(meetup_topics)
dim(meetup_topics)
head(meetup_topics)
```

```{r echo=TRUE}
## Unnest nested list using unnest of package tidyr
meetup_topics_unnested <- unnest(meetup_topics)
names(meetup_topics_unnested) <- c("group_id","urlkey","name","topic_id")

## Extract topics only
topics <- unique(meetup_topics_unnested[2:4])

## Export data into .csv without observation number
file_name_base = "topics"
file_name = paste("../data/",file_name_base,".csv",sep = "")
write.csv(topics, file_name, row.names = FALSE, fileEncoding = "UTF-8", quote = TRUE)

topics <- 
  read_csv(
    file_name,
    trim_ws = TRUE,
    col_names = names(topics),
    skip=1)

## Check data
str(topics)

## Add column with sequence number to be used as VID
seq_offset <- nrow(topics)
seq_start <- seq_last
seq_end <- seq_start + seq_offset - 1
topics$VID <- c(seq.int(from=seq_start,to=seq_end,by=1))
seq_last <- seq_end + 1

## Reshape the data (leaving out original Meetup IDs), pushing columns into rows for the various types of information to store about each node and edge.

## Nodes:
##   Create a dataframe containing all nodes
nodes.topic.type <-
  topics %>% 
  select(VID) %>% 
  mutate(key='type') %>% 
  mutate(datatype=str_dt) %>% 
  mutate(strval = 'Topic') %>% 
  mutate(numval=NA) %>% 
  mutate(datval=NA)
nodes.topic.type

nodes.topic.name <- 
  topics %>% 
  select(VID) %>% 
  mutate(key='topic_name') %>% 
  mutate(datatype=str_dt) %>% 
  bind_cols(select(topics,c(name))) %>% rename(strval='name') %>% 
  mutate(numval=NA) %>% 
  mutate(datval=NA)
## Remove empty values
nodes.topic.name <- nodes.topic.name[!is.na(nodes.topic.name$strval),]
nodes.topic.name

nodes.topic.urlkey <- 
  topics %>% 
  select(VID) %>% 
  mutate(key='topic_urlkey') %>% 
  mutate(datatype=str_dt) %>% 
  bind_cols(select(topics,c(urlkey))) %>% rename(strval='urlkey') %>% 
  mutate(numval=NA) %>% 
  mutate(datval=NA)
## Remove empty values
nodes.topic.urlkey <- nodes.topic.urlkey[!is.na(nodes.topic.urlkey$strval),]
nodes.topic.urlkey

## Join all TOPICS nodes together
nodes.topics <-
  bind_rows(
    nodes.topic.type, 
    nodes.topic.name, 
    nodes.topic.urlkey)

## Eliminate duplicates (just to be safe)
nodes.topics <- unique(nodes.topics)

View(nodes.topics)

## Edges:
##   Create a dataframe containing all edges

##   Edge: Topic - is_assigned_to - Group

## Join different data frames
topics_rel_topicgroups <- merge(x = topics, y = meetup_topics_unnested, by.x = "topic_id", by.y = "topic_id")
topics_rel_groups <- merge(x = topics_rel_topicgroups, y = groups, by.x = "group_id", by.y = "id")
topics_rel_groups <- topics_rel_groups[,c("VID.x","VID.y")]

seq_offset <- nrow(topics_rel_groups)
seq_start <- seq_last
seq_end <- seq_start + seq_offset - 1
topics_rel_groups$EID <- c(seq.int(from=seq_start,to=seq_end,by=1)) 
seq_last <- seq_end + 1

edges.topics.group <- 
  topics_rel_groups %>% 
  select(EID) %>% 
  bind_cols(select(topics_rel_groups,c(VID.x))) %>% rename(node_1='VID.x') %>% 
  bind_cols(select(topics_rel_groups,c(VID.y))) %>% rename(node_2='VID.y') %>% 
  mutate(label='is_assigned_to') %>% 
  mutate(key='%20') %>%
  mutate(datatype=NA) %>%
  mutate(strval=NA) %>%
  mutate(numval=NA) %>%
  mutate(datval=NA)
edges.topics.group

## Join all TOPICS edges together
edges.topics <-
  bind_rows(
    edges.topics.group)

## Eliminate duplicates (just to be safe)
edges.topics <- unique(edges.topics)
  
View(edges.topics)

Sys.sleep(10)
```

#### Bind all nodes and edges as Oracle Flat Files
Nodes file: meetup.opv  
Edges file: meetup.ope  
```{r echo=TRUE}
## Nodes:

nodes <- 
  nodes.cities %>%
  bind_rows(nodes.categories) %>%
  bind_rows(nodes.groups) %>%
  bind_rows(nodes.members) %>%
  bind_rows(nodes.events) %>%
  bind_rows(nodes.topics)  

## Replace special chars in nodes
nodes$strval <- replace_special_chars(nodes$strval)

## Rename columns according to structure of a vertex record
names(nodes) <- c("vertex_ID","key_name","value_type","strValue","numValue","datValue")
nodes

## Sort the dataset by VID
nodes <-
  nodes %>%
  arrange(vertex_ID)

View(nodes)
  
## Write to .opv (flat file). Replace NA values with ''. No header.
file_name_base = "meetup"
file_name = paste("../data/",file_name_base,".opv",sep = "")
write.table(nodes, file = file_name, row.names = FALSE, col.names = FALSE, fileEncoding = "UTF-8", quote = FALSE, na='', sep = ",")

## Edges:

edges <- 
  edges.groups %>%
  bind_rows(edges.events) %>%
  bind_rows(edges.members) %>%
  bind_rows(edges.topics)

## Rename columns according to structure of a edge record
names(edges) <- c("edge_ID","source_ID","dest_ID","e_label","key_name","value_type","strValue","numValue","datValue")
edges

## Sort the dataset by EID
edges <-
  edges %>%
  arrange(edge_ID)

View(edges)
  
## Write to .ope (flat file). Replace NA values with ''. No header.
file_name_base = "meetup"
file_name = paste("../data/",file_name_base,".ope",sep = "")
write.table(edges, file = file_name, row.names = FALSE, col.names = FALSE, fileEncoding = "UTF-8", quote = FALSE, na='', sep = ",")

```
Open file system and check exported nodes (meetup.opv) and edges (meetup.ope) files.

